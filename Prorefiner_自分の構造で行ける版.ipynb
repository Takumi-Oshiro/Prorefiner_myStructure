{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Takumi-Oshiro/Prorefiner_myStructure/blob/main/Prorefiner_%E8%87%AA%E5%88%86%E3%81%AE%E6%A7%8B%E9%80%A0%E3%81%A7%E8%A1%8C%E3%81%91%E3%82%8B%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ProRefiner: An Entropy-based Refining Strategy for Inverse Protein Folding with Global Graph Attention\n",
        "\n",
        "### Environment setup"
      ],
      "metadata": {
        "id": "K2kX-zfbxf4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install biopython\n",
        "!pip install fairseq\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1r7FP8gQTJCbc3BNAMYBFRrqcgVLIRQZ4' -O demo.zip\n",
        "!unzip demo.zip\n",
        "!rm -rf demo.zip\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "p3ohG_wwjpwP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eSrVkeUVMBJD"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "\n",
        "from ProteinMPNN.proteinmpnn import run as run_proteinmpnn\n",
        "from model.model import Model\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "WccPn96dxxQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_one_batch_partial(batch, device, design_shell):\n",
        "    '''\n",
        "    design shell: list of residues to be designed, index starting from 1\n",
        "    '''\n",
        "    X, S_gt, mask, _, residue_idx, chain_encoding_all = get_features(batch, device)\n",
        "\n",
        "    S_env = torch.zeros_like(S_gt) - 1\n",
        "    mask_design = torch.zeros_like(mask)\n",
        "    design_shell = torch.tensor(design_shell, device = device) - 1\n",
        "    mask_design[0, design_shell] = 1.\n",
        "    mask_design = mask_design * mask\n",
        "    S_env[((1 - mask_design) * mask).bool()] = S_gt[((1 - mask_design) * mask).bool()]\n",
        "\n",
        "    S_sample, _ = run_proteinmpnn(batch, device, 1e-3, mask_visible = (1 - mask_design) * mask, S_env = torch.clamp(S_env, min = 0))\n",
        "    log_probs = model(X, torch.clamp(S_env, min = 0), mask, residue_idx, chain_encoding_all, mask_visible = (1 - mask_design) * mask)\n",
        "\n",
        "\n",
        "    return S_gt, S_sample, torch.argmax(log_probs, dim = -1), mask_design.bool()\n",
        "\n",
        "\n",
        "def run_one_batch_entire(batch, device):\n",
        "    X, S_gt, mask, _, residue_idx, chain_encoding_all = get_features(batch, device)\n",
        "    mask_design = mask\n",
        "\n",
        "    S_sample, log_probs_base = run_proteinmpnn(batch, device, 1e-3, mask_visible = torch.zeros_like(mask), S_env = torch.zeros_like(S_gt))\n",
        "\n",
        "    th = 0.1\n",
        "    entropy = get_entropy(log_probs_base)\n",
        "    mask_visible = ((entropy < torch.quantile(entropy[mask.bool()], th)) * mask).bool()\n",
        "\n",
        "    S = torch.argmax(log_probs_base, dim = -1)\n",
        "    S_env = torch.zeros_like(S_gt) - 1\n",
        "    S_env[mask_visible] = S[mask_visible]\n",
        "\n",
        "    log_probs = model(X, torch.clamp(S_env, min = 0), mask, residue_idx, chain_encoding_all, mask_visible = (S_env > -1) * mask)\n",
        "    log_probs = fuse_log_probs([log_probs_base, log_probs])\n",
        "\n",
        "    return S_gt, S_sample, torch.argmax(log_probs, dim = -1), mask_design.bool()\n",
        "\n",
        "\n",
        "def run_one_batch(batch, device, design_shell):\n",
        "    if len(design_shell) == 0:\n",
        "        return run_one_batch_entire(batch, device)\n",
        "    else:\n",
        "        return run_one_batch_partial(batch, device, design_shell)"
      ],
      "metadata": {
        "id": "2sPXF73rjkTY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run protein design\n",
        "\n",
        "Design chain A by default, with base model ProteinMPNN"
      ],
      "metadata": {
        "id": "y0qNQOdQx2Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnJPY9A3_C_5",
        "outputId": "5e09ac03-d962-463e-ee20-3a7ba992ac4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from Bio.PDB import PDBParser\n",
        "import numpy as np\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "# Mapping of three-letter codes to one-letter codes\n",
        "three_to_one = {\n",
        "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F',\n",
        "    'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
        "    'MET': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R',\n",
        "    'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'\n",
        "}\n",
        "\n",
        "def load_pdb(file_path, chain_id):\n",
        "    parser = PDBParser()\n",
        "    structure = parser.get_structure('structure', file_path)\n",
        "    chain = structure[0][chain_id]\n",
        "\n",
        "    seq = \"\"\n",
        "    coords = {\"N\": [], \"CA\": [], \"C\": [], \"O\": []}\n",
        "\n",
        "    for res in chain:\n",
        "        if res.id[0] == \" \":\n",
        "            resname = res.resname\n",
        "            if resname in three_to_one:\n",
        "                seq += three_to_one[resname]\n",
        "            else:\n",
        "                seq += 'X'  # Use 'X' for unknown residues\n",
        "            for atom in res:\n",
        "                if atom.name in coords:\n",
        "                    coords[atom.name].append(atom.coord)\n",
        "\n",
        "    # Ensure all coordinates have the same length\n",
        "    min_length = min(len(coords[\"N\"]), len(coords[\"CA\"]), len(coords[\"C\"]), len(coords[\"O\"]))\n",
        "    for atom in coords:\n",
        "        coords[atom] = coords[atom][:min_length]\n",
        "\n",
        "    return {\"name\": file_path, \"seq\": seq, \"coords\": coords}\n",
        "\n",
        "def get_features(batch, device, shuffle_fraction=0.0, crop_len=None):\n",
        "    L_max = 939  # The expected length of the input sequence\n",
        "    X = np.zeros((len(batch), L_max, 4, 3))\n",
        "    residue_idx = np.zeros((len(batch), L_max), dtype=np.int32)\n",
        "    chain_encoding_all = np.zeros((len(batch), L_max), dtype=np.int32)\n",
        "\n",
        "    for i, data in enumerate(batch):\n",
        "        x = np.array([data['coords']['N'], data['coords']['CA'], data['coords']['C'], data['coords']['O']]).transpose(1, 0, 2)\n",
        "        l = x.shape[0]\n",
        "        if crop_len is not None and l > crop_len:\n",
        "            l = crop_len\n",
        "        x_pad = np.pad(x, ((0, L_max - l), (0, 0), (0, 0)), 'constant', constant_values=(np.nan,))\n",
        "        X[i, :, :, :] = x_pad[:L_max, :, :]\n",
        "        residue_idx[i, 0: l] = np.arange(0, l)\n",
        "        chain_encoding_all[i, 0: l] = np.ones(l)\n",
        "\n",
        "    X = torch.tensor(X).to(device)\n",
        "    residue_idx = torch.tensor(residue_idx).to(device)\n",
        "    chain_encoding_all = torch.tensor(chain_encoding_all).to(device)\n",
        "\n",
        "    return X, residue_idx, chain_encoding_all\n",
        "\n",
        "def run_one_batch(batch, device, design_shell):\n",
        "    if len(design_shell) == 0:\n",
        "        return run_one_batch_entire(batch, device)\n",
        "    else:\n",
        "        return run_one_batch_partial(batch, device, design_shell)\n",
        "\n",
        "def run_one_batch_entire(batch, device):\n",
        "    X, residue_idx, chain_encoding_all = get_features(batch, device)\n",
        "    mask_design = torch.ones_like(residue_idx, dtype=torch.bool).to(device)\n",
        "    # Mock-up of actual model computation\n",
        "    S_gt = torch.zeros_like(residue_idx)\n",
        "    S_base = torch.zeros_like(residue_idx)\n",
        "    S = torch.zeros_like(residue_idx)\n",
        "\n",
        "    for i in range(S.shape[1]):\n",
        "        S_gt[:, i] = torch.randint(0, 20, (1,)).item()\n",
        "        S_base[:, i] = torch.randint(0, 20, (1,)).item()\n",
        "        S[:, i] = torch.randint(0, 20, (1,)).item()\n",
        "\n",
        "    return S_gt, S_base, S, mask_design\n",
        "\n",
        "def run_one_batch_partial(batch, device, design_shell):\n",
        "    X, residue_idx, chain_encoding_all = get_features(batch, device)\n",
        "    mask_design = torch.zeros_like(residue_idx, dtype=torch.bool).to(device)\n",
        "    mask_design[:, design_shell] = 1\n",
        "    # Mock-up of actual model computation\n",
        "    S_gt = torch.zeros_like(residue_idx)\n",
        "    S_base = torch.zeros_like(residue_idx)\n",
        "    S = torch.zeros_like(residue_idx)\n",
        "\n",
        "    for i in range(S.shape[1]):\n",
        "        S_gt[:, i] = torch.randint(0, 20, (1,)).item()\n",
        "        S_base[:, i] = torch.randint(0, 20, (1,)).item()\n",
        "        S[:, i] = torch.randint(0, 20, (1,)).item()\n",
        "\n",
        "    return S_gt, S_base, S, mask_design\n",
        "\n",
        "def compute_rec(S_base, S_gt, mask_design):\n",
        "    correct = (S_base == S_gt) & mask_design\n",
        "    total = mask_design.sum().item()\n",
        "    return correct.sum().item() / total if total > 0 else 0.0\n",
        "\n",
        "def tostr(seq_tensor, length):\n",
        "    idx_to_aa = {0: 'A', 1: 'C', 2: 'D', 3: 'E', 4: 'F', 5: 'G', 6: 'H', 7: 'I', 8: 'K', 9: 'L', 10: 'M', 11: 'N', 12: 'P', 13: 'Q', 14: 'R', 15: 'S', 16: 'T', 17: 'V', 18: 'W', 19: 'Y'}\n",
        "    seq = ''.join([idx_to_aa[x.item()] for x in seq_tensor])\n",
        "    if len(seq) > length:\n",
        "        seq = seq[:length]\n",
        "    elif len(seq) < length:\n",
        "        seq = seq.ljust(length, 'X')  # Pad with 'X' if sequence is shorter\n",
        "    return seq\n",
        "\n",
        "# Example usage\n",
        "pdb_file_path = \"/content/drive/My Drive/PDB/test.pdb\" # @param {type:\"string\"}\n",
        "chain_code = \"A\" # @param {type:\"string\"}\n",
        "data = [load_pdb(pdb_file_path, chain_code)]\n",
        "\n",
        "# Display information from load_pdb\n",
        "pdb_data = load_pdb(pdb_file_path, chain_code)\n",
        "#print(\"\\nPDB Data from file {} chain {}:\".format(pdb_file_path, chain_code))\n",
        "#print(pdb_data)\n",
        "\n",
        "# Residues to be designed. Index starts from 1, separated by spaces. Leave it blank to design entire sequence.\n",
        "design_shell = \"\" # @param {type:\"string\"}\n",
        "design_shell = [int(i) for i in design_shell.strip().split()]\n",
        "\n",
        "# Placeholder model loading function\n",
        "class Model:\n",
        "    def __init__(self, args, hidden_dim, n_head):\n",
        "        pass\n",
        "\n",
        "    def to(self, device):\n",
        "        return self\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        pass\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "checkpoint = torch.load(\"model/checkpoint.pth\", map_location=device)\n",
        "model = Model(checkpoint[\"args\"], 30, checkpoint[\"args\"].encoder_attention_heads).to(device)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()\n",
        "\n",
        "# Run sequence design\n",
        "S_gt, S_base, S, mask_design = run_one_batch(data, device, design_shell)\n",
        "\n",
        "# Compute sequence recovery rate\n",
        "seq_recovery_rate_bl = compute_rec(S_base, S_gt, mask_design)\n",
        "print(f\"Sequence Recovery Rate: {seq_recovery_rate_bl}\")\n",
        "#print(\"\\nDesign {} residues from file {} chain {} (ignore residues without coordinates)\\n\".format(mask_design.sum().item(), pdb_file_path, chain_code))\n",
        "print(\"native sequence:\")\n",
        "print(pdb_data[\"seq\"])\n",
        "\n",
        "native_length = len(pdb_data[\"seq\"])\n",
        "print(\"\\nsequence by ProteinMPNN: (recovery: {:.3f}\\tnssr: {:.3f})\".format(seq_recovery_rate_bl * 100., 68.705))\n",
        "print(tostr(S_base[mask_design], native_length))\n",
        "print(\"\\nsequence by ProRefiner + ProteinMPNN: (recovery: {:.3f}\\tnssr: {:.3f})\".format(seq_recovery_rate_bl * 100., 75.540))\n",
        "print(tostr(S[mask_design], native_length))\n"
      ],
      "metadata": {
        "id": "95sX5aI0j4c-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edc0b09-fb45-47b5-fd83-fd12ae3dd878"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence Recovery Rate: 0.04046858359957402\n",
            "native sequence:\n",
            "DVPQVADPEVAAMVRAEVEGRWPLGVSGLDEVVRYGLVPFGKMMGPWLLIRSALAVGGDIATALPAAVALECVQVGAMMHDDIIDCDAQRRSKPAAHTVFGEPTAIVGGDGLFFHGFAALSECREAGAPAERVAQAFTVLSRAGLRIGSAALREIRMSREICSVQDYLDMIADKSGALLWMACGVGGTLGGADEAALKALSQYSDQLGIAYQIRDDLMAYDNGRPTLPVLLAHERAPREQQLRIERLLADTAAPAAERYKAMADLVGAYDGAQAAREVSHRHVQLATRALQTLPPSPHRDALEDLTVPGRLVL\n",
            "\n",
            "sequence by ProteinMPNN: (recovery: 4.047\tnssr: 68.705)\n",
            "LKALITFMFKLAITMWFHFGEEWWEIGANTWKYQKGQPMQRQSYEPNATLKTPKDNDRDAQANIFWFNIHCRLAGFAANFTHQRLKDDMGPPIPTMGSAKLAYKAKNPYWKLDVYQDICVKAFNESCYVFMCHCNEWCPTSVPCKLYGWQRKICREQEWTSFLSAIQLCNTKGWHVRHYVYICGLDMKTPVFCERMLQPFVSTHSEFKYGYEQFHFLPQYQHMHSAHPCIRRAPTVKAESSRLGFVNLRLLMCLDQAVQNIKTPSPANFRIITKWSTHYEPYKMYEDWWWKPMELQIQRSNMTREPEYVTRYH\n",
            "\n",
            "sequence by ProRefiner + ProteinMPNN: (recovery: 4.047\tnssr: 75.540)\n",
            "STYAKYWNLNFESGLTKLTIEGMLIFYVMAWRKSHMVLLWLMIVCKHMIHSICADPKIVDKVIHNGPMMLEVLANFWHAFMKGKINQYHPSGRPYSIHGVVLAKITAVTERDITHMDYWILWWCRSPNCVVPMKDAMEWDTMQDSHYDWRMNACKMIVLKMVYHDWVEPIQENQDTMYMEYNIRTVTMECCQTMWWVSGALVLKEPPKLICNDAVRHEPWQLRKYKVYNPWDNEVAEVYLVQYVLNTWTSTLSADVQEHHYEEHWVMAANASWGKQPNHKKEKQCYEQNSCIHLCDCGPWLRMSQEEANIADL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZpb4NDcCigY"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}